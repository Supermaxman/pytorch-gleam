seed_everything: 1
model:
  class_path: pytorch_gleam.modeling.models.ContrastiveFrameStanceLanguageModel
  init_args:
    learning_rate: 1e-5
    lr_warm_up: 0.0
    pre_model_name: digitalepidemiologylab/covid-twitter-bert-v2
    num_val_seeds: 1
    # ln(2) for pos/neg prob ratio of 2
    # TODO now needs to consider seq_len:
    # pos - neg + margin/seq_len > 0
    # ln(100) for pos/neg prob ratio of 100
    # ln(1000)
    # ln(10.0) <= 2.303 <= ln(10.01)
    # e^margin = perplexity ratio
    # ln(100)
    margin: 2.303
    infer:
      class_path: pytorch_gleam.inference.MultiHopConsistencyScoring
      init_args:
        num_steps: 0
        num_classes: 3
    threshold:
      class_path: pytorch_gleam.modeling.thresholds.MultiClassMultiLabelThresholdModule
    metric:
      class_path: pytorch_gleam.modeling.metrics.F1PRMultiClassMetric
      init_args:
        mode: macro
        num_classes: 3
    m_metric:
      class_path: pytorch_gleam.modeling.metrics.F1PRMultiClassMetric
      init_args:
        mode: micro
        num_classes: 3

trainer:
  max_epochs: 100
  accumulate_grad_batches: 4
  check_val_every_n_epoch: 4
  deterministic: true
  num_sanity_val_steps: 0
  accelerator: gpu
  devices: 1
  gradient_clip_val: 1.0
  track_grad_norm: 2
  default_root_dir: /shared/hltdir4/disk1/team/data/models/clearml/cvf-cp-v4
  enable_checkpointing: false
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      project: "icwsm2024"
      save_dir: /shared/hltdir4/disk1/team/data/models/clearml
      dir: /shared/hltdir4/disk1/team/data/models/clearml
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: pytorch_lightning.callbacks.RichProgressBar
      init_args:
        leave: true
    - class_path: pytorch_gleam.callbacks.FitCheckpointCallback
    - class_path: pytorch_gleam.callbacks.WandbConfig
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: val_f1
        patience: 2
        mode: max
    # - class_path: pytorch_gleam.callbacks.JsonlWriter
data:
  class_path: pytorch_gleam.data.datasets.ContrastiveFrameStanceDataModule
  init_args:
    batch_size: 4
    pos_samples: 1
    neg_samples: 1
    max_seq_len: 384
    num_workers: 8
    tokenizer_name: digitalepidemiologylab/covid-twitter-bert-v2
    frame_path: /shared/hltdir4/disk1/team/data/corpora/co-vax-frames/covid19/frames-covid19.json
    train_path: /shared/hltdir4/disk1/team/data/corpora/co-vax-frames/covid19/co-vax-frames-train.jsonl
    val_path: /shared/hltdir4/disk1/team/data/corpora/co-vax-frames/covid19/co-vax-frames-dev.jsonl
    test_path: /shared/hltdir4/disk1/team/data/corpora/co-vax-frames/covid19/co-vax-frames-test.jsonl
